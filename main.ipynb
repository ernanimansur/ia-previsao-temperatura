{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "from keras.layers import InputLayer, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o modelo treinado e historico salvos \n",
    "# model = load_model(\"modelos_historico/NOME.keras\")\n",
    "\n",
    "# with open(\"modelos_historico/different_data.pkl\", \"rb\") as file:\n",
    "#   history = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para salvar todos os dados em um novo arquivo csv\n",
    "def load_data():\n",
    "  # Lista para armazenar os DataFrames individuais\n",
    "  dfs = []\n",
    "\n",
    "  # Carregar os dados\n",
    "  for year in range(2007, 2025):\n",
    "    file_path = f'./data/INMET_MG_PAMPULHA_{year}.csv'\n",
    "    df = pd.read_csv(file_path, sep=';', encoding='latin1')\n",
    "\n",
    "    # Adicionar o DataFrame lido à lista\n",
    "    dfs.append(df)\n",
    "\n",
    "  # Concatenar todos os DataFrames em um único DataFrame\n",
    "  data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "  # Renomear colunas\n",
    "  data.columns = ['Data', 'Hora', 'Precipitação', 'Pressão atmosférica', 'Pressão Atmosférica MAX Hora Ant.',\n",
    "                  'Pressão Atmosférica MIN Hora Ant.', 'Radiação solar', 'Temperatura ar', 'Temperatura orvalho', \n",
    "                  'Temperatura MAX Hora Ant.', 'Temperatura MIN Hora Ant.', 'Temperatura Orvalho MAX Hora Ant.', \n",
    "                  'Temperatura Orvalho MIN Hora Ant.', 'Umidade MAX Hora Ant.', 'Umidade MIN Hora Ant.',\n",
    "                  'Umidade', 'Direção vento', 'Rajada vento', 'Velocidade vento']\n",
    "\n",
    "  # Remover \"UTC\" da coluna de tempo\n",
    "  data['Hora'] = data['Hora'].str.replace(' UTC', '')\n",
    "  # Converter a hora do formato \"HHMM\" para \"HH:MM\"\n",
    "  data['Hora'] = data['Hora'].apply(lambda x: f\"{x[:2]}\")\n",
    "  # Converter data e hora para datetime\n",
    "  data['datetime'] = pd.to_datetime(data['Data'] + ' ' + data['Hora'], format='%d/%m/%Y %H')\n",
    "  # Conversão para Unix Timestamp\n",
    "  data['unix_timestamp'] = data['datetime'].apply(lambda dt: dt.timestamp())\n",
    "\n",
    "  # Definir 'datetime' como índice e remover as colunas originais de data e hora\n",
    "  data = data.set_index('datetime')\n",
    "  data = data.drop(columns=['Data', 'Hora'])\n",
    "\n",
    "  # Preencher valores ausentes\n",
    "  data = data.replace(-9999, np.nan)\n",
    "  data = data.ffill().bfill()\n",
    "\n",
    "  # Remover linhas com NaN e o índice\n",
    "  data = data.dropna()\n",
    "\n",
    "  # Salva os dados relevantes para o treinamento em um novo arquivo csv\n",
    "  data.to_csv('all_data.csv', sep=';', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executa a função e salva tudo em um arquivo csv\n",
    "load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega os dados\n",
    "data = pd.read_csv('all_data.csv', sep=';', encoding='latin1')\n",
    "data = data.set_index('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plota matriz de correlação\n",
    "del_data = ['Pressão Atmosférica MAX Hora Ant.', 'Pressão Atmosférica MIN Hora Ant.', 'Temperatura MAX Hora Ant.', 'Temperatura MIN Hora Ant.', \n",
    "            'Temperatura Orvalho MAX Hora Ant.', 'Temperatura Orvalho MIN Hora Ant.', 'Umidade MAX Hora Ant.', 'Umidade MIN Hora Ant.',]\n",
    "\n",
    "correlation_matrix = data.drop(columns=del_data, axis=1).corr()\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=0.5)\n",
    "plt.gcf().text(0.43, -0.08, r'$\\bf{Figura\\ 1:}$ Correlação entre os dados meteorológicos', ha='center', fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara os dados para o treinamento\n",
    "\n",
    "# Remove colunas do treinamento\n",
    "del_data = ['Pressão Atmosférica MAX Hora Ant.', 'Pressão Atmosférica MIN Hora Ant.', 'Temperatura MAX Hora Ant.', 'Temperatura MIN Hora Ant.', \n",
    "            'Temperatura Orvalho MAX Hora Ant.', 'Temperatura Orvalho MIN Hora Ant.', 'Umidade MAX Hora Ant.', 'Umidade MIN Hora Ant.',]\n",
    "\n",
    "X = data.drop(columns=del_data, axis=1).values\n",
    "y = data['Temperatura ar'].values\n",
    "\n",
    "# Dividir os dados em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normaliza os dados\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Verificar o shape dos dados divididos\n",
    "print(\"Shape de X_train:\", X_train.shape)\n",
    "print(\"Shape de X_test:\", X_test.shape)\n",
    "print(\"Shape de y_train:\", y_train.shape)\n",
    "print(\"Shape de y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede Neural\n",
    "model = Sequential([\n",
    "  InputLayer(shape=(X_train.shape[1], 1)),\n",
    "  Conv1D(filters=32, kernel_size=3, activation='tanh', kernel_regularizer=l2(0.01)),\n",
    "  MaxPooling1D(pool_size=2),\n",
    "  Flatten(),\n",
    "  Dense(16, activation='tanh', kernel_regularizer=l2(0.01)),\n",
    "  Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer= Adam(learning_rate=1e-3) , loss='mae', metrics=[RootMeanSquaredError()])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, start_from_epoch=100)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=128, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "# Salva o modelo treinado e historico (MAE e RMSE)\n",
    "# model.save('model_history/best_model.keras')\n",
    "\n",
    "# with open(\"model_history/history_best_model.pkl\", \"wb\") as file:\n",
    "#   pickle.dump(history.history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar a perda\n",
    "fig_loss, axs_loss = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "\n",
    "# Plotar a perda\n",
    "axs_loss[0].plot(history.history['loss'], label='Perda de Treinamento')\n",
    "axs_loss[0].plot(history.history['val_loss'], label='Perda de Validação')\n",
    "axs_loss[0].set_xlabel('Épocas')\n",
    "axs_loss[0].set_ylabel('Custo')\n",
    "axs_loss[0].legend()\n",
    "axs_loss[0].grid(True)\n",
    "\n",
    "# Plotar a perda - zoom\n",
    "axs_loss[1].plot(history.history['loss'], label='Perda de Treinamento')\n",
    "axs_loss[1].plot(history.history['val_loss'], label='Perda de Validação')\n",
    "axs_loss[1].set_ylim([0.05, 0.165])\n",
    "axs_loss[1].set_xlabel('Épocas')\n",
    "axs_loss[1].set_ylabel('Custo')\n",
    "axs_loss[1].legend()\n",
    "axs_loss[1].grid(True)\n",
    "\n",
    "fig_loss.text(0.5, 0, r'$\\bf{Figura\\ 2a:}$ Custo em função das épocas.', ha='center', fontsize=12)\n",
    "fig_loss.tight_layout()\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "# Plotar a RMSE\n",
    "fig_metrics, axs_metrics = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "\n",
    "# Plotar RMSE\n",
    "axs_metrics[0].plot(history.history['root_mean_squared_error'], label='RMSE de Treinamento')\n",
    "axs_metrics[0].plot(history.history['val_root_mean_squared_error'], label='RMSE de Validação')\n",
    "axs_metrics[0].set_xlabel('Épocas')\n",
    "axs_metrics[0].set_ylabel('RMSE')\n",
    "axs_metrics[0].legend()\n",
    "axs_metrics[0].grid(True)\n",
    "\n",
    "# Plotar RMSE - zoom\n",
    "axs_metrics[1].plot(history.history['root_mean_squared_error'], label='RMSE de Treinamento')\n",
    "axs_metrics[1].plot(history.history['val_root_mean_squared_error'], label='RMSE de Validação')\n",
    "axs_metrics[1].set_ylim([0.05, 0.145])\n",
    "axs_metrics[1].set_xlabel('Épocas')\n",
    "axs_metrics[1].set_ylabel('RMSE')\n",
    "axs_metrics[1].legend()\n",
    "axs_metrics[1].grid(True)\n",
    "\n",
    "fig_metrics.text(0.5, 0, r'$\\bf{Figura\\ 2b:}$ Erro Quadrático Médio em função das épocas.', ha='center', fontsize=12)\n",
    "fig_metrics.tight_layout()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar o modelo\n",
    "mae, rmse = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Model loss (MAE): {mae} \\nRMSE: {rmse}')\n",
    "\n",
    "y_pred = model.predict(X_test, verbose=0)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R square (R²): {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plota as temperaturas reais e previstas \n",
    "index = np.arange(len(y_pred))\n",
    "\n",
    "# Plotar os dados reais e previstos no mesmo gráfico\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.scatter(index, y_test, color='blue', label='Dados Reais', alpha=0.7)\n",
    "plt.scatter(index, y_pred, color='red', label='Dados Previstos')\n",
    "plt.xlabel('Número de Dados')\n",
    "plt.ylabel('Temperatura (°C)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.gcf().text(0.5, 0, r'$\\bf{Figura\\ 3:}$ Comparação entre temperaturas previstas e reais.', ha='center', fontsize=12)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plota a diferença entre as temperaturas reais e previstas \n",
    "\n",
    "y_pred_wrong = []\n",
    "y_test_wrong = []\n",
    "\n",
    "y_pred_right = []\n",
    "y_test_right = []\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "  if np.round(y_pred[i][0], decimals=1) != y_test[i]:\n",
    "    y_pred_wrong.append( y_pred[i][0] )\n",
    "    y_test_wrong.append( y_test[i] )\n",
    "  else:\n",
    "    y_pred_right.append( y_pred[i][0] )\n",
    "    y_test_right.append( y_test[i] )\n",
    "\n",
    "residue_wrong = np.array(y_test_wrong) - np.array(y_pred_wrong)\n",
    "index_wrong = np.arange(len(residue_wrong))\n",
    "\n",
    "residue_right = np.array(y_test_right) - np.array(y_pred_right)\n",
    "index_right = np.arange(len(residue_right))\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(20, 8))\n",
    "\n",
    "axs[0].scatter(index_right, residue_right, color='green')\n",
    "axs[0].axhline(y=0, color='black', linestyle='dashed')\n",
    "axs[0].set_xlabel('Valores ajustados')\n",
    "axs[0].set_ylabel('Resíduos')\n",
    "axs[0].grid(True)\n",
    "\n",
    "axs[1].scatter(index_wrong, residue_wrong, color='green')\n",
    "axs[1].axhline(y=0, color='black', linestyle='dashed')\n",
    "axs[1].set_xlabel('Valores ajustados')\n",
    "axs[1].set_ylabel('Resíduos')\n",
    "axs[1].grid(True)\n",
    "\n",
    "fig.text(0.25, -0.02, r'$\\bf{Figura\\ 4a:}$ Diferença entre temperatura real e temperatura prevista (valores próximos).', ha='center', fontsize=12)\n",
    "fig.text(0.75, -0.02, r'$\\bf{Figura\\ 4b:}$  Diferença entre temperatura real e temperatura prevista (valores diferentes).', ha='center', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
